class PCA:
    def __init__(self, target_explained_variance=None):
        """
        explained_variance: float, the target level of explained variance
        """
        self.target_explained_variance = target_explained_variance
        self.feature_size = -1

    def standardize(self, X):
        """
        standardize features using standard scaler
        :param X: input data with shape m (# of observations) X n (# of features)
        :return: standardized features (Hint: use skleanr's StandardScaler. Import any library as needed)
        """
        from sklearn.preprocessing import StandardScaler
        sc = StandardScaler()
        X_std = sc.fit_transform(X)
        return X_std

    def compute_mean_vector(self, X_std):
        """
        compute mean vector
        :param X_std: transformed data
        :return n X 1 matrix: mean vector
        """
        mean_vec = X_std.mean(axis=0)
        return mean_vec
        

    def compute_cov(self, X_std, mean_vec):
        """
        Covariance using mean, (don't use any numpy.cov)
        :param X_std:
        :param mean_vec:
        :return n X n matrix:: covariance matrix
        """
        cov_mat = np.zeros((X_std.shape[1],X_std.shape[1]))
        for i in range(X_std.shape[1]):
            cov_mat[:,i] = (X_std[:,i] - mean_vec[i]) @ (X_std[:,i] - mean_vec[i]).T / (X_std.shape[0]-1)
        
        return cov_mat
        

    def compute_eigen_vector(self, cov_mat):
        """
        Eigenvector and eigen values using numpy. Uses numpy's eigenvalue function
        :param cov_mat:
        :return: (eigen_values, eigen_vector)
        """
        eigen_values, eigen_vector = np.linalg.eig(cov_mat)
        
        return eigen_values, eigen_vector

    def compute_explained_variance(self, eigen_vals):
        """
        sort eigen values and compute explained variance.
        explained variance informs the amount of information (variance)
        can be attributed to each of  the principal components.
        :param eigen_vals:
        :return: explained variance.
        """
        eigen_vals = np.sort(eigen_vals)
        totla_var = np.sum(eigen_vals)
        explained_variance = eigen_vals / totla_var
        return explained_variance

    def cumulative_sum(self, var_exp):
        """
        return cumulative sum of explained variance.
        :param var_exp: explained variance
        :return: cumulative explained variance
        """
        return np.cumsum(var_exp)

    def compute_weight_matrix(self, eig_pairs, cum_var_exp):
        """
        compute weight matrix of top principal components conditioned on target
        explained variance.
        (Hint : use cumilative explained variance and target_explained_variance to find
        top components)
        
        :param eig_pairs: list of tuples containing eigenvalues and eigenvectors, 
        sorted by eigenvalues in descending order (the biggest eigenvalue and corresponding eigenvectors first).
        :param cum_var_exp: cumulative expalined variance by features
        :return: weight matrix (the shape of the weight matrix is n X k)
        """

        top_principal_components = []
        for i in range(cum_var_exp.shape[0]):
            
            if cum_var_exp[i] >= self.target_explained_variance:
                print(i)
                z = eig_pairs[0:i+1]
                for j in range(len(z)):
                    top_principal_components.append(z[j][1])
                y = np.zeros((cum_var_exp.shape[0],i+1))
                for c in range(len(z)):
                    y[:,c]=top_principal_components[c]
                break
            
        weight_matrix = y
    
        return weight_matrix
    def transform_data(self, X_std, matrix_w):
        """
        transform data to subspace using weight matrix
        :param X_std: standardized data
        :param matrix_w: weight matrix
        :return: data in the subspace
        """
        return X_std.dot(matrix_w)

    def fit(self, X):
        """    
        entry point to the transform data to k dimensions
        standardize and compute weight matrix to transform data.
        The fit functioin returns the transformed features. k is the number of features which cumulative 
        explained variance ratio meets the target_explained_variance.
        :param   m X n dimension: train samples
        :return  m X k dimension: subspace data. 
        """
    
        self.feature_size = X.shape[1]
        
        # your code here
        X_std = self.standardize(X)
        
        mean_vec = self.compute_mean_vector(X_std)
        
        cov_mat = self.compute_cov(X_std, mean_vec)
        
        eigen_values, eigen_vector = self.compute_eigen_vector(cov_mat)
        
        explained_variance = self.compute_explained_variance(eigen_values)
        
        cum_var_exp = self.cumulative_sum(explained_variance)
        
        eigen_values = np.sort(eigen_values)
        
        eig_pairs = []

        for i in range(eigen_values.shape[0]):
            eig_pairs.append((eigen_values[i] , eigen_vector[:,i]))
            
        matrix_w = self.compute_weight_matrix(eig_pairs, cum_var_exp)
        
        print(len(matrix_w),len(matrix_w[0]))
        return self.transform_data(X_std=X_std, matrix_w=matrix_w)
